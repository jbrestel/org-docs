#+STARTUP: indent
#+SETUPFILE: https://fniessen.github.io/org-html-themes/org/theme-readtheorg.setup
#+TITLE:     EDA DIY
#+AUTHOR:    John Brestelli
#+DESCRIPTION: EDA DIY
#+OPTIONS:   H:5 num:nil toc:2 p:t tags:not-in-toc
* Background / Overview

DIY EDA will allow a user to walk up to our ClinEpi or MBio site and load a Study.

- First deliverable for ClinEpi is 1:1 File per EntityType, no ontology mapping, and simple dataset description
- Future ClinEpi releases may deal with mutliple files/entitytypes, mapping ontology terms, and other attribute info like publications, contacts...
- We want to reuse existing plugins from EDA Load
- We have a Parallel schema "EDA_UD"
  - the study table has one extra field for "user_dataset_id"
- Plugins are made to load into either schema

- Here is a pretty picture from DanG about [[https://veupathdb.atlassian.net/wiki/spaces/UI/pages/19661442/ClinEpi+DIY+Dataset+Import+Backend+Changes][User Datasets]]

#+name: Another view of the Process Flow
#+begin_src plantuml :file images/eda_diy.png :exports results
start
if(isMbio) then (yes)
  :Validate biom;
 else(no)
  :Validate tab delim;
endif
if(isValid) then (yes)
  :IRODs;
  rectangle Installer {
  if(isMbio) then (yes)
    :preprocess biom;
  else(no)
    :preprocess tab delim;
  endif
  :load externaldatabases;
  :load ontologyterms;
  :load entity graph;
  :load studydataset;
        }
else (no)
  :Exit and Report Errors;
endif

stop
#+end_src

#+RESULTS: Another view of the Process Flow
[[file:images/eda_diy.png]]

* Validator                                                                                                       :JayH:

Write some python code.  The parent is in python.

- [X] Wojtek has some tests for biom handler; confirm fresh checkout can run and pass tests
  - [X] add some readme text describing how to run these

- [X] Confirm We will need separate validators for Mbio and ClinEpi

- [X] Where does the validator code live?  is this built in a container?

   [[github:VEuPathDB/dataset-handler-biom]]

   ValidationException :: User submitted a bad  file
   BaseException :: Some random error.  User should email us

- [X] mbio to use Use existing biom validator?
  - [X] Are there additional requirements for metadata table?... NO!

* Installer

- exportInvestigation.pl can be called in the Validator or Installer (for legacy user datasets in IRODs)
  - [X] Create ontology files
    - [X] Entity Types (mbio will have 2 rows.  ClinEpi one row per file)
    - [X] Variables/Attributes
  - [X] ISASimple data file
  - [X] ISASimple ancilary files (use ontology term source_ids from above)
    - [X] "investigation.xml" file for the study
    - [X] ontologyMapping.xml

- [X] Because preprocessing SOPs change we will store raw user data in iRODs.
  - [X] installer will process the data and make it conform to plugin specs

- [ ] how to run singularity on any jenkins/server?  is singularity installed on ash?.. NO!
  - [ ] BobB add singularity on irodsn and irodss

- [X] Plugins require a GUS environment.
  - "bld GUS" creates the perl object layer by reading from db instance specified in gus.config
  - UserDataset installers up til now share a gus environment.  they don't make perl objects
    - Example:  irods.builder on [[https:ws.apidb.org]]
  - [X] create a container which has a gus environment
    - [[github:veupathdb/dataset-installer-isasimple]]
  - [X] can't create perl objects during docker build so for now we can stuff them in the manually

- [X] one of the plugins makes a system call to singularity to run an RScript from plot.data
  - [X] put the plot.data code in the container

- [X] one of the plugins uses sql*loader
  - [X] put the oracle instant client tools in the container

- [X] need access to GUS_HOME on jenkins.
  - [X] $GUS_HOME/config/gus.config specifies the database
  - [X] the login/user in these gus.config files is ApidbUserDatasets
  - [X] bind the file into the container

- [X] Assume Dependent data like Ontology Term Types are loaded by Reflow Worfklow and available to UserDataset Installer.  Things like "Ontology Term Types"

- [X] add user_dataset_id to appropriate eda_ud tables and add studydataset table
  - [X] sql to be run after "createEntityGraph" tables in schema installer:  [[github:veupathdb/ApiCommonData/tree/master/Load/lib/sql/apidbschema/createEdaUdModifications.sql][createEdaUdModifications.sql]]
  - [X] EDA_UD.StudyDataset
    - this should mirror what we have in apidbtuning.datasetpresenter + ApiDBTuning.StudyIdDatasetId
    - begin with minimal info (name, description, ID)
    - [X] Requires a unique id for the study/dataset.  Will just store the user dataset id??

- [X] Follow up with Ann/Dave to make sure uncategorized variables are ok.

- [ ] Confirm mbio can genreate ISASimple file from biom

** Example files

#+name: Household.txt
| Household ID | Parent | h_attr1      | h_attr2        | h_attr3      |
|--------------+--------+--------------+----------------+--------------|
| hh_id1       |        | h_attr1_val1 | h_attr2_value1 | h_attr3_val1 |
| hh_id2       |        | h_attr1_val2 | h_attr2_value2 | h_attr3_val2 |
| hh_id3       |        | h_attr1_val2 | h_attr2_value3 | h_attr3_val3 |

#+name: Participant.txt
| Participant ID | Parent | p_attr1      | p_attr2        | p_attr3      |
|----------------+--------+--------------+----------------+--------------|
| p_id1          | hh_id1 | p_attr1_val1 | p_attr2_value1 | p_attr3_val1 |
| p_id2          | hh_id2 | p_attr1_val2 | p_attr2_value2 | p_attr3_val2 |
| p_id3          | hh_id3 | p_attr1_val2 | p_attr2_value3 | p_attr3_val3 |



** Use existing plugins / workflow

bash script with the following plugins configured.

*** ExternalDatabase and ExternalDatabaeRelease
- [X] GUS::Supported::Plugin::InsertExternalDatabase
- [X] GUS::Supported::Plugin::InsertExternalDatabaseRls

*** Insert "Ontology" (EntityTypes, Variables and Protocols?)
- [X] GUS::Supported::Plugin::InsertOntologyFromTabDelim
  - This will load into OntologyTerm and OntologySynonym

*** Insert Entity Graph
  - [X] ApiCommonData::Load::Plugin::InsertEntityGraph
  - [X] ApiCommonData::Load::Plugin::LoadAttributesFromEntityGraph
  - [X] ApiCommonData::Load::Plugin::LoadEntityTypeAndAttributeGraphs
  - [X] ApiCommonData::Load::Plugin::LoadDatasetSpecificEntityGraph
  - [X] No need to load StudyCharacteristics

*** Insert StudyDataset table                                                                                  :JohnB:
The EDA requires a dataset record.  Steve's proposal is to create a UserDatasetPresenter table which can be installed along with other data.
NOTE:  The User Dataset metadata is not sufficient as we need a wdk record not simply the user dataset page.
- [X] Table(s) for the Dataset


* Undo for Installer
- [X] create script which manages undo (given user dataset id)
- [X] confirm that undo mechanism can handle tables which do not have a user_dataset_id (SRes tables)

   #+name: Ontology Undo
   #+begin_src sql
     delete blah from sres.ontologyterm where ontology_term_id in (
	select distinct ontology_term_id from eda_ud.attribute where user_dataset_id = ?
	union
	select distinct ontology_term_id from eda_ud.entitytype where user_dataset_id = ?
	union
	...
     )
#+end_src

** Steps to delete a study

1. [X] find study_id and internal abbrev (input is user_dataset_id)
2. [X] find entity_type_id and internal abbrev (input is study_id)
3. [X] find external_database_release_id for study
4. [X] find external_database_id for study
5. [X] find external_database_release_id for ontology terms
6. [X] find external_database_id for ontology terms
7. [X] Delete dataset specific tables
   - ANCESTORS_${studyAbbrev}_${entityTypeAbbrev}
   - ATTRIBUTEGRAPH_${studyAbbrev}_${entityTypeAbbrev}
   - ATTRIBUTEVALUE_${studyAbbrev}_${entityTypeAbbrev}
8. [X] delete EntityTypeGraph by study_id
9. [X] delete AttributeGraph by study_id
10. [X] delete attributeunit by entity_type_id
11. [X] delete attribute by entity_type_id
12. [X] delete processattributes by linking to entityattributes
13. [X] delete entityattributes by entity_type_id
14. [X] delete attributevalue by entity_type_id
15. [X] delete EntityType by study_id
16. [X] delete study by study_id
17. [X] delete studydataset by study_id
18. [X] delete studycharacteristict by study_id
19. [X] delete sres.ontologyrelationship by external_database_release_id
20. [X] delete sres.ontologysynonym by external_database_release_id
21. [X] delete sres.externaldatabaserelease (2)
22. [X] delete sres.externaldatabase (2)


* TODO Model + other Schema
- [ ] Create View which unions apidbtuning.datasetpresener with eda_ud.studydataset
- [ ] For all relevant dataset record attributes and tables... need to use the View (above) which is a union of the datasetpresenter tables and the eda_ud dataset tables
- [ ] Create views which unions EDA.EntityType and EDA_UD.EntityType ... maybe others?


* Misc
- [X] can ApidbUserDatasets user run a plugin (need ApidbUserDatasets in Core.UserInfo;  ProjectUser and GroupUser tables need rows)?
  - [X] Add a workflow step (eda-inc and mbio) which will add ApidbUserDatasets and associate with row(s) in core.projectinfo and core.groupinfo
- Existing UX for Microbiome biom files should remain in place.  ClinEpi DIY will need to consume 1 or more tab files and the user should be able to specifiy the "parent" entity type for each file
- versioning in user datasets is for what is stored in irods.  Add optional preprocessing/transform stept to installer.  This should give us flexibility (ie. if the raw data has not changed, we are free to switch around the installer steps)
- How does user dataset access differ from "study access"
- Infra team is making a flat file dumper to help with performance.  we'll need to make these files for user datasets too.  We cannot put them in apiSiteFiles as those are sync'd.   Likely we'll copy them to a dedicated directory.
