#+STARTUP: indent
#+SETUPFILE: https://fniessen.github.io/org-html-themes/org/theme-readtheorg.setup
#+TITLE:     EDA DIY
#+AUTHOR:    John Brestelli
#+DESCRIPTION: EDA DIY
#+OPTIONS:   H:5 num:nil toc:2 p:t tags:not-in-toc

* Overview

Because preprocessing may change for clinep (and already has for mbio) we will store both raw and preprocessed data in iRODs.  The initial validator step will make the transformed/preprocessed files.  The Installer will check if needed files are available and create if necessary.

#+name: Process Flow
#+begin_src plantuml :file images/eda_diy.png :exports results
start
if(isMbio) then (yes)
  :Validate biom;
  :preprocess biom;
 else(no)
  :Validate tab delim;
  :preprocess tab delim;
endif
if(isValid) then (yes)
  :IRODs;
  rectangle Installer {
  if(missingPreprocessedFiles) then (yes)
    if(isMbio) then (yes)
      :preprocess biom;
    else(no)
      :preprocess tab delim;
    endif
  else (no)
  endif
   :load ontologyterms;
   :load entity graph;
   :load attribution;
        }
else (no)
  :Exit and Report Errors;
endif

stop
#+end_src

#+RESULTS: Process Flow
[[file:images/eda_diy.png]]

- [ ] confirm that we run "touch GusSchema/Definition/config/gus_schema.xml; bld GUS" which creates the GUS model objects
- [ ] add user_dataset_id to each eda_ud table
  - [ ] sql to be run after "createEntityGraph" tables in schema installer
- [X] need access to GUS_HOME on jenkins.
  - [X] $GUS_HOME/config/gus.config specifies the database
- [ ] Create EDA_UD tables to store Attribution/Dataset info
  - this should mirror what we have in apidbtuning.datasetpresenter
  - begin with minimal info (name, description, ID)
  - [ ] Requires a unique id for the study/dataset.  Can we just store the user dataset id??

* Validator

- [X] Confirm We will need separate validators for Mbio and ClinEpi
- [ ] Where does the validator code live?  is this built in a container?
- [ ] each entitytype must have at least on variable/attribute
- [ ] mbio to use Use existing biom validator?
  - [ ] Are there additional requirements for metadata table?
- [ ] Clinepi first deliveralbe, there will be a single file (one entity type)
  - What can we validate?
    - every row must have a primary key
    - pk must be unique
    - col headers must be unique

* Preprocess/Transform Script

These scripts can be called in the Validator or Installer (for legacy user datasets in IRODs)

- [ ] Create ontology files
  - [ ] Entity Types (mbio will have 2 rows.  ClinEpi one row per file)
  - [ ] Variables/Attributes
  - [ ] Protocols?  Check if these are required

- [ ] ISASimple data file

- [ ] ISASimple ancilary files (use ontology term source_ids from above)
  - [ ] "investigation.xml" file for the study
  - [ ] ontologyMapping.xml? is this needed?

* Installer

- Example:  irods.builder on [[https://ws.apidb.org]]

- [ ] Confirm mbio can genreate ISASimple file from biom

** Example files

#+name: Household.txt
| Household ID | Parent | h_attr1    | h_attr2      | h_attr3    |
|--------------+--------+------------+--------------+------------+
| hh_id1       |        | attr1_val1 | attr2_value1 | attr3_val1 |
| hh_id2       |        | attr1_val2 | attr2_value2 | attr3_val2 |
| hh_id3       |        | attr1_val2 | attr2_value3 | attr3_val3 |

#+name: Participant.txt
| Household ID | Parent | h_attr1    | h_attr2      | h_attr3    |
|--------------+--------+------------+--------------+------------|
| p_id1        | hh_id1 | attr1_val1 | attr2_value1 | attr3_val1 |
| p_id2        | hh_id2 | attr1_val2 | attr2_value2 | attr3_val2 |
| p_id3        | hh_id3 | attr1_val2 | attr2_value3 | attr3_val3 |


** Use existing plugins / workflow

*** ExternalDatabase and ExternalDatabaeRelease
- [ ] GUS::Supported::Plugin::InsertExternalDatabase
- [ ] GUS::Supported::Plugin::InsertExternalDatabaseRls

*** Insert "Ontology" (EntityTypes, Variables and Protocols?)
- [ ] GUS::Supported::Plugin::InsertOntologyFromTabDelim
  - This will load into OntologyTerm and OntologySynonym

*** Insert Entity Graph
  - [ ] ApiCommonData::Load::Plugin::InsertEntityGraph
  - [ ] ApiCommonData::Load::Plugin::LoadAttributesFromEntityGraph
  - [ ] ApiCommonData::Load::Plugin::LoadEntityTypeAndAttributeGraphs
  - [ ] ApiCommonData::Load::Plugin::LoadDatasetSpecificEntityGraph


*** Insert Dataset tables
The EDA requires a dataset record.  Steve's proposal is to create a UserDatasetPresenter table which can be installed along with other data.
NOTE:  The User Dataset metadata is not sufficient as we need a wdk record not simply the user dataset page.

- [ ] Table(s) for the Dataset, Contact, PumedID (bib ref), ...
- [ ] Create View which unions apidbtuning.datasetpresener with eda_ud.datasetpresenter

* Undo for Installer!!!
- [ ] create script which manages undo (given user dataset id)
- [ ] confirm that undo mechanism can handle tables which do not have a user_dataset_id (SRes tables)

   #+name: Ontology Undo
 #+begin_src sql
     delete blah from sres.ontologyterm where ontology_term_id in (
	select distinct ontology_term_id from eda_ud.attribute where user_dataset_id = ?
	union
	select distinct ontology_term_id from eda_ud.entitytype where user_dataset_id = ?
	union
	...
     )
#+end_src


* WDK Model
- [ ] For all relevant dataset record attributes and tables... need to use the View (above) which is a union of the datasetpresenter tables and the eda_ud dataset tables
- [ ] Fix the general look of the dataset record page.  The UD version should only have the minimal info (name and description) for now


* UX
  Existing UX for Microbiome biom files should remain in place.  ClinEpi DIY will need to consume 1 or more tab files and the user should be able to specifiy the "parent" entity type for each file

* What to do about legacy user datasets?
versioning in user datasets is for what is stored in irods.  Add optional preprocessing/transform stept to installer.  This should give us flexibility (ie. if the raw data has not changed, we are free to switch around the installer steps)

* Study access
** TODO How does user dataset access differ from "study access"
